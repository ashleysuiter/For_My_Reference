{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Using Transformed Variables in Regression Models"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The phrase \"feature engineering\" refers to methods of transforming the feature variables for a model in order to improve model performance. This lesson discusses feature engineering in the context of linear regression, but the techniques it demonstrates are more broadly applicable."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import pandas as pd\n", "import seaborn as sns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load mammals data set\n", "mammals_path = Path('..', 'assets', 'data', 'mammals.txt')\n", "cols = ['brain', 'body']\n", "mammals = pd.read_csv(mammals_path, sep='\\t', names=cols, header=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (10 mins.)**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Drop mammals with body weight above 200 kg."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Create a linear regression model of brain weight against body weight: $\\mbox{brain} = \\beta_0 + \\beta_1 * \\mbox{body}$"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Superimpose a line plot of the fitted values from that model on a scatterplot of the individual data points."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Linear regression creates a model that is linear in terms of features that you pass into it. **But linear regression can capture non-linear relationships with your original features if you give it non-linear transformations of those features.**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For instance, the code below fits this model:\n", "\n", "$\\mbox{brain} = \\beta_0 + \\beta_1 * \\mbox{body} + beta_2 * \\mbox{body}^2$"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Re-run the regression with an additional squared term\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot the resulting model on top of the corresponding scatterplot\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Polynomial Terms"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A polynomial function of x has the form $c_0 + c_1x + c_2x^2 + c_3x^3 + \\ldots$.\n", "\n", "If you give a linear regression model $x$, $x^2$, and $x^3$ as features, for instance, it will find the $\\beta_0$, $\\beta_1$, $\\beta_2$, and $\\beta_3$ that minimizes mean-squared error for using $\\beta_0 + \\beta_1x + \\beta_2x^2 + \\beta_3x^3$ to predict $y$.\n", "\n", "It can always recover simple linear regression by setting the coefficients on the higher-order terms to 0, so adding these higher-order terms only increases the set of relationships that the model can capture."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (1 min., post answers right away.)**\n", "\n", "- How does adding higher-order polynomial terms as inputs to a linear regression model affect its bias and variance?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Every additional polynomial term gives your model an additional chance to change directions.**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# first-order\n", "x = np.linspace(-1, 1, 100)\n", "plt.plot(x, x);"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# second-order\n", "plt.plot(x, x**2);"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# third-order\n", "x = np.linspace(-.75, 1.5, 100)\n", "plt.plot(x, -.4*x - x**2 + x**3);"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# fourth-order\n", "x = np.linspace(-1, 1, 100)\n", "plt.plot(x, -x**2 + x**4);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Too many polynomial terms leads to overfitting"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 8th-order model\n", "g = sns.lmplot(x='body', y='brain', data=mammals, ci=None, order=8);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["An (n-1)-order polynomial can always fit n data points perfectly. It is definitely overfitting!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 50th-order model\n", "fig = sns.lmplot(x='body', y='brain', data=mammals, ci=None, order=50);\n", "ax = fig.axes\n", "ax[0,0].set_ylim(0, 200);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Including multiple transformations of one variable complicates coefficient interpretation."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Print intercept and coefficients from second-order model we created earlier\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (2 mins., post answers right away)**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Write down the equation of this second-order model (with fitted coefficient values)."]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- How would you normally interpret the coefficient on `body` in a linear regression model of brain weight against body weight? Why doesn't that interpretation work in this case?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**sklearn has a \"transformer\" that generates polynomial terms**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# sklearn transformers have the same interface as \"estimators\" (models)\n", "# except that you fit them on features and use them to transform features,\n", "# rather than fitting them on features and a target and using them to predict\n", "# target values.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A transformer returns a modified copy of the object it acts on without changing that objects in place."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (10 mins., pair programming)**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Use the Boston housing data for the exercises below."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["from sklearn.datasets import load_boston\n", "\n", "boston = load_boston()\n", "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n", "y = pd.DataFrame(boston.target, columns=['MEDV'])\n", "boston = pd.concat([X, y], axis=1)\n", "boston.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Create a linear regression model for MEDV against DIS with no higher-order polynomial terms."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Create a linear regression model for MEDV against DIS with polynomial terms for DIS up to and including degree seven."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- **Bonus:** Create line plots of your models' fitted values as a function of DIS and overlay them on scatterplots of MEDV against DIS.\n", "\n", "*Tip:* You need to plot your model's predictions against DIS only. If the result looks like spaghetti, then you probably need to sort on DIS. Either sort the DataFrame on DIS from the beginning, or use the `.argsort()` method to get the sequence of row numbers that would sort it on DIS, and use that sequence to select rows for both x and y."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- **Bonus:** Create a model with $DIS$ and $DIS^{-1}$ as features and plot its predictions overlayed on a scatterplot of MEDV against DIS."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Notes.**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- In statistics, it is extremely unusual to use more than a third-order polynomial. It is more common in machine learning, where the emphasis tends to be on predictive accuracy rather than understanding.\n", "- It would be unusual to use a polynomial term without including all lower-order polynomial terms.\n", "- In addition to polynomial terms (with positive integer exponents), it can also be beneficial to include terms with negative exponents (e.g. $x^{-1}=1/x$) and/or fractional exponents (e.g. $x^{1/2}=\\sqrt{X}$)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's use 5-fold cross-validation to choose the polynomial order between 1 and 10 that gives the best results in terms of MSE on held-out data, taking advantage of the scikit-learn convenience function `cross_val_score`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (4 mins.)** \n", "\n", "- Create a model with $DIS$ and $DIS^{-1}$ as features and score it using 5-fold cross-validation."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Interaction Terms"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Sometimes the significance of one feature depends on the value of another feature.\n", "\n", "For instance, perhaps median housing prices increase as you get closer to a major employment center *unless crime is high around that area*."]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can model these kinds of \"interaction effects\" by including the *products* of the interacting variables as features in our models.\n", "\n", "For example:\n", "\n", "$$MEDV = \\beta_0 + \\beta_1 * DIS + \\beta_2 * CRIM + \\beta_{12} (DIS * CRIM)$$"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Implement the model above\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (2 mins., post answers right away.)**\n", "\n", "- Write down the fitted model we just created."]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# check descriptive stats\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Recall the usual interpretation of the coefficient on DIS:** how much the model's prediction for MEDV changes with a one-unit increase in DIS, all else being equal (i.e. for a particular value of CRIM).\n", "\n", "**With interaction terms, interpreting the coefficients for a feature DIS requires specifying particular values for the interacting variables.**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For instance, if CRIM is fixed at its 25th percentile value of 0.082, we get\n", "\n", "$MEDV = 22.62 + 0.48 * DIS + 0.467 * CRIM - 0.527 (DIS * CRIM)$\n", "\n", "$MEDV = 22.62 + 0.48 * DIS + 0.467 * 0.082 - 0.527 (DIS * 0.082)$\n", "\n", "$MEDV = 22.62 + 0.48 * DIS + 0.038 - 0.043 * DIS$\n", "\n", "$MEDV = 22.658 + 0.437 * DIS$\n", "\n", "So **at CRIM=.082**, the model's prediction for MEDV increases by .437 when DIS increases by one. It's better on average to be away from employment centers when crime is low.\n", "\n", "The story is different when CRIM has its 75th percentile value of 3.64:\n", "\n", "$MEDV = 22.62 + 0.48 * DIS + 0.467 * CRIM - 0.527 (DIS * CRIM)$\n", "\n", "$MEDV = 22.62 + 0.48 * DIS + 0.467 * 3.64 - 0.527 (DIS * 3.64)$\n", "\n", "$MEDV = 22.62 + 0.48 * DIS + 1.70 - 1.92 * DIS$\n", "\n", "$MEDV = 24.32 -1.44 * DIS$\n", "\n", "**At CRIM=3.64**, the model's prediction for MEDV *decreases* by 1.44 when DIS increases by one. It's better on average to be close to employment centers when crime is high."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (8 mins., pair programming)**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- How does adding interaction terms affect a model's bias and variance?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Using 5-fold cross-validation, calculate the MSE for a model predicting MEDV from DIS and CRIM without an interaction term. *Hint*: use sklearn.model_selection.cross_val_score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Using 5-fold cross-validation, calculate the MSE for a model predicting MEDV from DIS and CRIM with an interaction term. *Hint*: use sklearn.model_selection.cross_val_score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- **Bonus:** Find the best model you can, as measured by MSE in 5-fold cross-validation."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Log Transformations"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When your data is very skewed, try a log transformation."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Plot histograms of mammal brain and body sizes\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot scatterplot of brain size against body size\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot histograms of mammal brain and body sizes after a log transformation\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot scatterplot of brain size against body size after log transformation\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Because we applied a log transformation to $y$ as well as $x$, we need to be careful about how we interpret the MSE values."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Train and score a linear model in the original space.\n", "# This model isn't overfitting significantly, so let's not\n", "# worry about a train/test split.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train and score a linear model in the log-transformed space.\n", "# This model isn't overfitting significantly, so let's not\n", "# worry about a train/test split.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Not a fair comparison! MSE for the second model is in log-space."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false}, "outputs": [], "source": ["# Get MSE for the log-log model in the original space\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**What's going on?**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["fix, ax = plt.subplots()\n", "ax.scatter(X, y);\n", "ax.plot(X, np.exp(y_pred_log));"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fix, ax = plt.subplots()\n", "ax.scatter(X, y);\n", "ax.plot(X, y_pred);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The model that we fit in log-log space is getting killed by the points in the top-right:\n", "\n", "- MSE punishes large errors.\n", "- Errors that are large in the original space don't look so large in log-log space, so the model doesn't focus on them as much as it \"should.\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["**So which model should you use?** Probably the log-log model.\n", "\n", "The original model is better if MSE of brain size prediction is **really** what you care about. But is being off by 1 kg when predicting elephant brain size really as bad as being off by 1 kg when predicting rabbit brain size? Maybe what we really care about is more like *percent error* in terms of number of kg -- that's what a model for the log of brain size optimizes for.\n", "\n", "In addition, the log-log model conveys more understanding: modeling log of brain size as a linear function of log of body size plus random noise seems to capture what is really going on."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('mean percent error of original model:', ((y-y_pred)/y).mean())\n", "print('mean percent error of model fit in log-log space:',\n", "      ((np.exp(y_log)-np.exp(y_pred_log)/np.exp(y))).mean()\n", "     )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Takeaways:**\n", "\n", "- When your data is highly skewed, try a log transformation.\n", "- When you evaluate a model that transforms $y$, make sure that you calculate metrics for different models on the same scale.\n", "- Make sure that the metric you are optimizing reflects what you care about."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Notes:**\n", "\n", "- A log-transformed variable typically replaces the original variable in a regression analysis, unlike a polynomial term.\n", "- You can apply a log transformation to any combination of your features and your target variable."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Summary\n", "\n", "- Linear regression *can* capture non-linear relationships *when you provide the appropriate non-linear transformations*.\n", "- Every polynomial term you add allows your model to change directions once.\n", "- Log transformations are appropriate for variables with highly skewed distributions."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.1"}}, "nbformat": 4, "nbformat_minor": 2}