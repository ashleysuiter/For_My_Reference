{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n", " \n", "# Logistic Regression"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Intro\n", "\n", "Tonight we are talking about logistic regression, which despite its name is a classification algorithm."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (2 mins.)** Slack poll.\n", "\n", "/poll \u201cWhich of the following are classification (as opposed to regression) problems? (Select all that apply.)\u201d \u201cPredicting how many people will come to a meetup event.\u201d \u201cPredicting which of the people who signed up for a meetup will actually attend.\u201d \u201cPredicting the price that a house will sell for, based on its zip code and square footage.\u201d \u201cAssigning probabilities of experiencing a fire in the next six months to buildings in a city.\u201d \u201cIdentifying animals in photographs by species.\u201d"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"refresher-fitting-and-visualizing-a-linear-regression-using-scikit-learn\"></a>\n", "# Refresher: Fitting and Visualizing a Linear Regression Using scikit-learn\n", "\n", "Use Pandas to load in the glass attribute data from the UCI machine learning website. The columns are different measurements of properties of glass that can be used to identify the glass type. For detailed information on the columns in this data set, [please see the included .names file](http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.names)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "\n", "import matplotlib.pyplot as plt\n", "import pandas as pd\n", "import seaborn as sns\n", "\n", "sns.set(font_scale=1.5);"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%matplotlib inline"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["glass_filepath = Path('..', 'assets', 'data', 'glass.csv')\n", "glass = pd.read_csv(glass_filepath)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# change columns to something more uniform\n", "glass.columns = ['ri', 'na', 'mg', 'al', 'si', 'k', 'ca', 'ba', 'fe', 'glass_type']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Data Dictionary**\n", "\n", "1. `ri`: refractive index\n", "- `na`: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 3-9)\n", "- `mg`: Magnesium\n", "- `al`: Aluminum\n", "- `si`: Silicon\n", "- `k` : Potassium\n", "- `ca`: Calcium\n", "- `ba`: Barium\n", "- `fe`: Iron\n", "- `glass_type`: type of glass:\n", "    - 1 building_windows_float_processed \n", "    - 2 building_windows_non_float_processed \n", "    - 3 vehicle_windows_float_processed \n", "    - 4 vehicle_windows_non_float_processed (none in this database) \n", "    - 5 containers \n", "    - 6 tableware \n", "    - 7 headlamps\n", "    \n", "The study of classification of types of glass was motivated by criminological investigation. At the scene of the crime, the glass left can be used as evidence, if it is correctly identified."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Inspect data\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Examine glass_type.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Let's build a regression model estimator for refractice index against aluminum content.**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create a scatter with a regression line\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (14 mins., in pairs)**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Instantiate and train a linear regression estimator called `linreg` to predict `ri` from `al` (and an intercept)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Add a column `y_pred` to `glass` that stores the estimator's fitted values for the refractice index."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Plot the predicted `ri` against each `al` as a line."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["_Note the y axis labels when comparing to the scatterplot above._"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Plot this regression line with the scatter points on the same chart. (Use the predictions from the sklearn model rather than calling Seaborn's lmplot function.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- How good would you say that this model is, based on the graph? Suggestion: think about how it compares to a \"null model\" that just predicts the mean reflective index regardless of the aluminum content."]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Print out the intercept and coefficient values from our trained `LinearRegression` estimator."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- What do these numbers mean?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Manually compute the predicted value of `ri` when `al=2.0` using the regression equation."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Confirm that this is the same value we would get when using the built-in `.predict()` method of the `LinearRegression` object."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"predicting-a-categorical-response\"></a>\n", "# Predicting a Single Categorical Response\n", "\n", "Linear regression is appropriate when we want to predict the value of a continuous target/response variable, but what about when we want to predict membership in a class or category?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Say these types are subdivisions of broader glass types:\n", "\n", "> **Window glass:** types 1, 2, and 3\n", "\n", "> **Household glass:** types 5, 6, and 7\n", "\n", "**Create a new `household` column that indicates whether or not a row is household glass, coded as 1 or 0, respectively.**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Types 1, 2, 3 are window glass.\n", "# Types 5, 6, 7 are household glass.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's change our task, so that we're predicting the `household` category using `al`. Let's visualize the relationship to figure out how to do this."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Make a scatter plot comparing `al` and `household`\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Fit a new `LinearRegression` predicting `household` from `al`.**\n", "\n", "Let's draw a regression line like we did before:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Fit a linear regression estimator and store the predictions.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false}, "outputs": [], "source": ["# Scatter plot that includes the regression line\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If **al=3**, what class do we predict for household? **1**\n", "\n", "If **al=1.5**, what class do we predict for household? **0**\n", "\n", "We predict the 0 class for **lower** values of al, and the 1 class for **higher** values of al. What's our cutoff value? Around **al=2**, because that's where the linear regression line crosses the midpoint between predicting class 0 and class 1.\n", "\n", "Therefore, we'll say that if **household_pred >= 0.5**, we predict a class of **1**, else we predict a class of **0**."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Using this threshold, create a new column of our predictions for whether a row is household glass.\n", "\n", "# np.where returns the first value if the condition is True,\n", "# and the second value if the condition is False.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Transform household_pred to 1 or 0.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# sort so we can have a continuous line\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot the class predictions.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Linear regression yields a reasonable binary classifier in this case when we map values above 0.5 to 1 and values below 0.5 to 0.\n", "\n", "**So why not just use linear regression for classification?**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Reason 1 to use logistic over linear regression for classification: pre-threshold output can be interpreted as probabilities"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It would be nice if we could also interpret the raw numbers it gives us, e.g. as probabilities. The problem is that linear regression is unbounded. As a result, it gives values below 0 and above 1, which cannot be probabilities.\n", "\n", "This is where logistic regression comes in: it basically takes that linear regression line and bends its ends into an S-shape so that it always stays between 0 and 1, so that we can interpret its outputs as probabilities."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Fit a logistic regression estimator and store the class predictions.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> **Aside:** Whereas linear regression minimizes squared error, logistic regression minimizes *log-loss* (also known as *cross-entropy*). See [this article](http://rasbt.github.io/mlxtend/user_guide/classifier/LogisticRegression/) for a detailed explanation."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Plot the predicted class using the logistic regression as we did for the linear regression predictions above.**\n", "\n", "As you will see, the class predictions are nearly the same in this case."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot the predicted class using the logistic regression as we did for the linear regression predictions above.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this case, the class predictions are nearly the same."]}, {"cell_type": "markdown", "metadata": {}, "source": ["What if we wanted the predicted probabilities instead of just the class predictions, to understand how confident we are in a given prediction?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Examine the predicted probabilities for the first handful of rows of `X`.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Sklearn orders the columns according to our class labels. The two-column output of `predict_proba` returns a column for each class of our `household` variable. The first column is the probability of `household=0` for a given row, and the second column is the probability of `household=1`.\n", "\n", "**Store the predicted probabilities of class=1 in its own column in the data set.**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Store the predicted probabilities of class 1.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot the predicted probabilities.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Examine some example predictions.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Reason 2 to use logistic rather than linear regression for classification: it handles \"influential points\" better."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Adding an extreme point. Don't worry about this code.\n", "glass_augmented = pd.concat([glass, glass.iloc[[-1], :]])\n", "glass_augmented.reset_index(inplace=True)\n", "glass_augmented.loc[214, ['al', 'household']] = [15, 1]\n", "glass_augmented.tail()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Linear regression line is greatly affected by the extreme point\n", "feature_cols = ['al']\n", "X = glass_augmented[feature_cols] \n", "y = glass_augmented.loc[:, 'household'] \n", "linreg.fit(X, y)\n", "glass_augmented.loc[:, 'household_pred'] = linreg.predict(X)\n", "\n", "ax = glass_augmented.plot(kind='scatter', x='al', y='household')\n", "glass_augmented.plot(x='al', y='household_pred', color='red', ax=ax);"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Predictions from thresholded linear regression line no longer look sensible\n", "glass_augmented.loc[:, 'household_pred_class'] = np.where(\n", "    glass_augmented.loc[:, 'household_pred'] >= 0.5, 1, 0\n", "    )\n", "glass_augmented.head()\n", "\n", "ax = glass_augmented.plot(kind='scatter', x='al', y='household')\n", "glass_augmented.plot(x='al', y='household_pred_class', color='red', ax=ax);"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Logistic regression handles this case much better, because the\n", "# model converges toward 1 instead of flying off to infinity.\n", "from sklearn.linear_model import LogisticRegression\n", "\n", "logreg = LogisticRegression()\n", "\n", "feature_cols = ['al']\n", "X = glass_augmented.loc[:, feature_cols]\n", "y = glass_augmented.loc[:, 'household']\n", "\n", "logreg.fit(X,y)\n", "pred = logreg.predict(X)\n", "\n", "glass_augmented.loc[:, 'household_pred_prob'] = logreg.predict_proba(X)[:, 1]\n", "ax = glass_augmented.plot(kind='scatter', x='al', y='household')\n", "glass_augmented.plot(x='al', y='household_pred_prob', c='r', ax=ax);"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax = glass_augmented.plot(kind='scatter', x='al', y='household')\n", "ax.plot(glass_augmented.loc[:, 'al'], np.array(pred), c='r');"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Summary**\n", "\n", "- You can think of logistic regression as taking linear regression and adapting it to classification problems by \"bending\" the regression line into a \"sigmoidal\" (s-like) shape that is bounded by 0 and 1.\n", "- Two result has at least two advantages over simply using linear regression with a threshold for classification:\n", "    - Before thresholding, it produces numbers that we can interpret as probabilities.\n", "    - Because it stays between 0 and 1 instead of flying off to infinity, it handles extreme points better."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (5 mins.)**\n", "\n", "- Build a logistic regression estimator for `household` using two features of your choice."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Do a simple train-test split on `glass`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Train your estimator on the training set and evaluate it with `.score` on the test set."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- **BONUS:** Try out different sets of features to see which give the best results."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"probability-odds-ratio-e-log-and-log-odds\"></a>\n", "## Understanding Logistic Regression\n", "---\n", "\n", "**Recall:** A coefficient in a *linear regression* model tells you how the *number* predicted by the model changes when the associated variable increases by one and all other variables remain the same.\n", "\n", "**Similarly**, A coefficient in a *logistic regression* model tells you how the *log odds* predicted by the model changes when the associated variable increases by one and all other variables remain the same."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's try to develop some intuitions about log odds to help us reason about our logistic regression models. *Understanding this material is helpful, but don't panic if it goes over your head -- you can get a long way without it.*"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Odds"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When outcomes are equally likely,\n", "\n", "$$\\text{probability} = \\frac {\\text{number of favorable outcomes}} {\\text{total number of possible outcomes}}$$\n", "\n", "$$\\text{odds} = \\frac {\\text{number of favorable outcomes}} {\\text{number\\ of\\ unfavorable\\ outcomes}}$$\n", "\n", "It is often useful to think of the numeric odds as a ratio. For example, 5/1 = 5 odds is \"5 to 1\" -- five wins for every one loss (e.g. of six total plays). 2/3 odds means \"2 to 3\" -- two wins for every three losses (e.g. of five total plays).\n", "\n", "Examples:\n", "\n", "- Dice roll of 1: probability = 1/6, odds = 1/5\n", "- Even dice roll: probability = 3/6, odds = 3/3 = 1\n", "- Dice roll less than 5: probability = 4/6, odds = 4/2 = 2\n", "\n", "$$\\text{odds} = \\frac {\\text{probability}} {1 - \\text{probability}}$$"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Create a table of probability versus odds.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (4 mins., in groups)**\n", "\n", "Convert the following probabilities to odds:\n", "\n", "- .25"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- 1/3"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- 2/3"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- .95"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"understanding-e-and-the-natural-logarithm\"></a>\n", "### Understanding the Natural Logarithm"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A logarithm tells you the *order of magnitude* of a number. The base-10 logarithm is a continuous version of \"the number of times you would need to multiply 10 to get that number.\"\n", "\n", "| number | number as a power of 10 | $\\log_{10}$(number) |\n", "| ------ | ----------------------------- | --- |\n", "| $1 $|$ 10^0$ | 0 |\n", "| $10 $|$ 10^1$ | 1 |\n", "| $100 $|$ 10^2$ | 2 |\n", "| $1000 $|$ 10^3$ | 3 |\n", "\n", "It also works in the other direction:\n", "\n", "| number | number as a power of 10 | $\\log_{10}$(number) |\n", "| ------ | ----------------------------- | -- |\n", "| $.001 $ | $ 10^{-3}$ | -3 |\n", "| $.01 $ | $ 10^{-2}$ | -2 |\n", "| $.1 $|$ 10^{-1}$ | -1 |\n", "| $1 $|$ 10^0$ | 0 |\n", "\n", "And for numbers in between exact powers of 10:\n", "\n", "| number | number as a power of 10 | $\\log_{10}$(number) |\n", "| ------ | ----------------------------- | -- |\n", "| $1$ | $ 10^{0}$ | 0 |\n", "| $2$ | $ 10^{.301}$ | .301 |\n", "| $5$|$ 10^{.699}$ | .699 |\n", "| $10$|$ 10^1$ | 1 |\n", "| $20$|$ 10^{1.301}$ | 1.301 |\n", "| $50$|$ 10^{1.699}$ | 1.699 |\n", "| $100$|$ 10^2$ | 2 |"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Base $e$.** It is often convenient to use the special number $e$ as a base instead of 10. The interpretation is analogous: the base-$e$ logarithm of a number is a continuous version of \"the number of times you would have to multiple $e$ to get that number.\"\n", "\n", "For instance:\n", "\n", "| number | number as a power of $e$ | $\\log_{e}$(number) |\n", "| ------ | ----------------------------- | - |\n", "| $1 $|$ e^0$ | 0 |\n", "| $2.718$|$ e^1$ | 1 |\n", "| $7.39$|$ e^2$ | 2 |\n", "| $20.09$|$ e^3$ | 3 |\n", "\n", "It also works in the other direction:\n", "\n", "| number | number as a power of $e$ | $\\log_{e}$(number) |\n", "| ------ | ----------------------------- | - |\n", "| $.050 $ | $ e^{-3}$ | -3 |\n", "| $.135 $ | $ e^{-2}$ | -2 |\n", "| $.368 $|$ e^{-1}$ | -1 |\n", "| $1 $|$ e^0$ | 0 |\n", "\n", "And for numbers in between exact powers of $e$:\n", "\n", "| number | number as a power of $e$ | $\\log_{e}$(number) |\n", "| ------ | ----------------------------- | - |\n", "| $1$ | $ e^{0}$ | 0 |\n", "| $1.35$ | $ e^{.301}$ | .301 |\n", "| $2.01$|$ e^{.699}$ | .699 |\n", "| $2.718$|$ e^1$ | 1 |\n", "| $3.67$|$ e^{1.301}$ | 1.301 |\n", "| $5.47$|$ e^{1.699}$ | 1.699 |\n", "| $7.39$|$ e^2$ | 2 |"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When we take the **logarithm** of an **odds** we get the **log odds**.\n", "\n", "The most common convention is to use base-$e$ logarithms unless otherwise specified."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add log odds to the table.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Notice:** log odds goes to $-\\infty$ as probability goes to 0, and goes to $\\infty$ as probability goes to 1.\n", "\n", "**Consequence:** The fact that linear model is unbounded is fine if we use it to model *log odds* rather than *probability*."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"what-is-logistic-regression\"></a>\n", "### What Is Logistic Regression?\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Linear regression:** *Continuous response* is modeled as a linear combination of the features.\n", "\n", "$$y = \\beta_0 + \\beta_1x$$\n", "\n", "**Logistic regression:** *Log odds* is modeled as a linear combination of the features.\n", "\n", "$$\\log \\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1x$$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This equation can be rearranged to get the predicted probability:\n", "\n", "$$\\hat{p} = \\frac{e^{\\beta_0 + \\beta_1x}} {1 + e^{\\beta_0 + \\beta_1x}}$$\n", "\n", "This equation gives us the \"S\" (sigmoid) shape for the predicted probability as a function of $\\beta_1$."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### How do we interpret the regression parameters?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Linear regression:**\n", "\n", "$$y = \\beta_0 + \\beta_1x$$\n", "\n", "- $\\beta_0$ tells you the model's prediction for $y$ when all input features are zero.\n", "- $\\beta_1$ tells you how the model's prediction for $y$ changes with a one-unit increase in $x$ when all other variables remain the same.\n", "\n", "**Logistic regression:**\n", "\n", "$$\\log \\left({p\\over 1-p}\\right) = \\beta_0 + \\beta_1x$$\n", "\n", "- $\\beta_0$ tells you the model's prediction for the *log odds of $y$* when all input features are zero.\n", "- $\\beta_1$ tells you how the model's prediction for *the log odds of* $y$ changes with a one-unit increase in $x$ when all other variables remain the same."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Bottom line:** A positive coefficient means that the predicted log odds of the response (and thus the predicted probability) increases with the associated variable, while a negative coefficient means that it decreases."]}, {"cell_type": "markdown", "metadata": {}, "source": ["![Logistic regression beta values](../assets/images/logistic_betas.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Changing the $\\beta_0$ value shifts the curve horizontally, whereas changing the $\\beta_1$ value changes the slope of the curve."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Summary\n", "\n", "- Logistic regression addresses a binary classification problem by modeling the *log odds* that an individual is in the class as a linear function of the model features.\n", "- A coefficient in a logistic regression model tells you *how the log odds that the model predicts changes* with a one-unit increase in the associated input feature, while other features remain unchanged.\n", "- The model's log-odds predictions can be transformed into *probabilities*.\n", "- Those predicted probabilities follow an \"s\" (sigmoid) shape that is bounded by 0 and 1, as a function of the input features.\n", "- Those predicted probabilities can be converted into \"hard\" class predictions by mapping everything above a threshold to 1 and everything below it to 0."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"comparing-logistic-regression-to-other-models\"></a>\n", "## Comparing Logistic Regression to Other Models\n", "---\n", "\n", "Advantages of logistic regression:\n", "\n", "- Somewhat interpretable.\n", "- Training and prediction are fast.\n", "- Outputs probabilities.\n", "- Features don't need scaling.\n", "- Can perform well with a small number of observations.\n", "\n", "Disadvantages of logistic regression:\n", "\n", "- Presumes a linear relationship between the features and the log odds of the response.\n", "- Performance is (generally) not competitive with the best supervised learning methods.\n", "- Can't automatically learn feature interactions."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"advanced-classification-metrics\"></a>\n", "# Classification Metrics Beyond Accuracy\n", "\n", "By default, the `.score` method of a logistic regression estimator in sklearn returns accuracy:\n", "\n", "$$\\text{Accuracy} = \\frac{\\text{total predicted correct}}{\\text{total predicted}}$$\n", "\n", "However, accuracy is not always the most relevant metric."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Consider the **confusion matrix** for a binary classification problem where we have 165 observations/rows of people who are either smokers or nonsmokers.\n", "\n", "<table style=\"border: none\">\n", "<tr style=\"border: none\">\n", "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n", "    <td style=\"\"><b>Predicted: No</b></td>\n", "    <td style=\"\"><b>Predicted: Yes</b></td>\n", "</tr>\n", "<tr>\n", "    <td><b>Actual: No</b></td>\n", "    <td style=\"text-align: center\"><font color=\"blue\">TN = 50</font></td>\n", "    <td style=\"text-align: center\"><font color=\"red\">FP = 10</font></td>\n", "    <td style=\"text-align: center\">60</td>\n", "</tr>\n", "<tr>\n", "    <td><b>Actual: Yes</b></td>\n", "    <td style=\"text-align: center\"><font color=\"orange\">FN = 5</font></td>\n", "    <td style=\"text-align: center\"><font color=\"green\">TP = 100</font></td>\n", "    <td style=\"text-align: center\">105</td>\n", "</tr>\n", "<tr style=\"border: none\">\n", "    <td style=\"border: none\"></td>\n", "    <td style=\"text-align: center\">55</td>\n", "    <td style=\"text-align: center\">110</td>\n", "</tr>\n", "\n", "</table>\n", "\n", "\n", "- <font color=\"green\">**True positives (TP):**</font> These are cases in which we predicted yes (smokers), and they actually are smokers.\n", "- <font color=\"blue\">**True negatives (TN):**</font> We predicted no, and they are nonsmokers.\n", "- <font color=\"red\">**False positives (FP):**</font> We predicted yes, but they were not actually smokers. (This is also known as a \"Type I error.\")\n", "- <font color=\"orange\">**False negatives (FN):**</font> We predicted no, but they are smokers. (This is also known as a \"Type II error.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (3 mins., in groups).**\n", "\n", "Categorize these cases as TP, TN, FP, or FN.\n", "    \n", "- We predict that a growth is malignant, and it is benign. (is_malignant=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- We predict that an image does not contain a cat, and it does not. (has_cat=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- We predict that a locomotive will fail in the next two weeks, and it does. (breaks=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- We predict that a user will like a song, and she does not. (likes_song=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"accuracy-true-positive-rate-and-false-negative-rate\"></a>\n", "### Accuracy, True Positive Rate, and False Negative Rate"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Accuracy:** Overall, how often is the classifier correct?\n", "\n", "<span>\n", "    (<span style=\"color: green\">TP</span>+<span style=\"color: blue\">TN</span>)/<span style=\"color: purple\">total</span> = (<span style=\"color: green\">100</span>+<span style=\"color: blue\">50</span>)/<span style=\"color: purple\">165</span> = 0.91\n", "</span>\n", "\n", "<table style=\"border: none\">\n", "<tr style=\"border: none\">\n", "    <td style=\"border: none; vertical-align: bottom; color: purple\">n = 165</td>\n", "    <td style=\"\"><b>Predicted: No</b></td>\n", "    <td style=\"\"><b>Predicted: Yes</b></td>\n", "</tr>\n", "<tr>\n", "    <td><b>Actual: No</b></td>\n", "    <td style=\"text-align: center; background-color: blue\">TN = 50</td>\n", "    <td style=\"text-align: center\">FP = 10</td>\n", "    <td style=\"text-align: center\">60</td>\n", "</tr>\n", "<tr>\n", "    <td><b>Actual: Yes</b></td>\n", "    <td style=\"text-align: center\">FN = 5</td>\n", "    <td style=\"text-align: center; background-color: green\">TP = 100</td>\n", "    <td style=\"text-align: center\">105</td>\n", "</tr>\n", "<tr style=\"border: none\">\n", "    <td style=\"border: none\"></td>\n", "    <td style=\"text-align: center\">55</td>\n", "    <td style=\"text-align: center\">110</td>\n", "</tr>\n", "\n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**True positive rate (TPR)** asks, \u201cOut of all of the target class labels, how many were accurately predicted to belong to that class?\u201d\n", "\n", "For example, given a medical exam that tests for cancer, how often does it correctly identify patients with cancer?\n", "\n", "<span>\n", "<span style=\"color: green\">TP</span>/<span style=\"color: aqua\">actual yes</span> = <span style=\"color: green\">100</span>/<span style=\"color: aqua\">105</span> = 0.95\n", "</span>\n", "\n", "<table style=\"border: none\">\n", "<tr style=\"border: none\">\n", "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n", "    <td style=\"\"><b>Predicted: No</b></td>\n", "    <td style=\"\"><b>Predicted: Yes</b></td>\n", "</tr>\n", "<tr>\n", "    <td><b>Actual: No</b></td>\n", "    <td style=\"text-align: center\">TN = 50</td>\n", "    <td style=\"text-align: center\">FP = 10</td>\n", "    <td style=\"text-align: center\">60</td>\n", "</tr>\n", "<tr>\n", "    <td><b>Actual: Yes</b></td>\n", "    <td style=\"text-align: center\">FN = 5</td>\n", "    <td style=\"text-align: center;background-color: green\">TP = 100</td>\n", "    <td style=\"text-align: center;color: aqua\">105</td>\n", "</tr>\n", "<tr style=\"border: none\">\n", "    <td style=\"border: none\"></td>\n", "    <td style=\"text-align: center\">55</td>\n", "    <td style=\"text-align: center\">110</td>\n", "</tr>\n", "\n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**False positive rate (FPR)** asks, \u201cOut of all items not belonging to a class label, how many were predicted as belonging to that target class label?\u201d\n", "\n", "For example, given a medical exam that tests for cancer, how often does it trigger a \u201cfalse alarm\u201d by incorrectly saying a patient has cancer?\n", "\n", "<span>\n", "<span style=\"color: orange\">FP</span>/<span style=\"color: fuchsia\">actual no</span> = <span style=\"color: orange\">10</span>/<span style=\"color: fuchsia\">60</span> = 0.17\n", "</span>\n", "\n", "<table style=\"border: none\">\n", "<tr style=\"border: none\">\n", "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n", "    <td style=\"\"><b>Predicted: No</b></td>\n", "    <td style=\"\"><b>Predicted: Yes</b></td>\n", "</tr>\n", "<tr>\n", "    <td><b>Actual: No</b></td>\n", "    <td style=\"text-align: center\">TN = 50</td>\n", "    <td style=\"text-align: center;background-color: orange\">FP = 10</td>\n", "    <td style=\"text-align: center;color:fuchsia\">60</td>\n", "</tr>\n", "<tr>\n", "    <td><b>Actual: Yes</b></td>\n", "    <td style=\"text-align: center\">FN = 5</td>\n", "    <td style=\"text-align: center\">TP = 100</td>\n", "    <td style=\"text-align: center\">105</td>\n", "</tr>\n", "<tr style=\"border: none\">\n", "    <td style=\"border: none\"></td>\n", "    <td style=\"text-align: center\">55</td>\n", "    <td style=\"text-align: center\">110</td>\n", "</tr>\n", "\n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (5 mins., in groups)**\n", "\n", "We turn the probabilities output by a logistic regression model into \"hard\" predictions by setting a threshold. For instance, we might treat all probabilities above .5 as positive predictions and the rest as negative predictions.\n", "\n", "- Does the true positive rate of a logistic regression model increase or decrease if we change the threshold probability for treating a prediction as positive from .5 to .6?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Does the false positive rate of a logistic regression model increase or decrease if we change the threshold probability for treating a prediction as positive from .5 to .6?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Describe a situation in which you would want to use a high threshold probability."]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Describe a situation in which you would want to use a low threshold probability."]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Calculate the accuracy, true positive rate, and false positive rate for the confusion matrix below.\n", "\n", "<table style=\"border: none\">\n", "<tr style=\"border: none\">\n", "    <td style=\"border: none; vertical-align: bottom\">n = 140</td>\n", "    <td style=\"\"><b>Predicted: No</b></td>\n", "    <td style=\"\"><b>Predicted: Yes</b></td>\n", "</tr>\n", "<tr>\n", "    <td><b>Actual: No</b></td>\n", "    <td style=\"text-align: center\">30</td>\n", "    <td style=\"text-align: center\">10</td>\n", "    <td style=\"text-align: center\">40</td>\n", "</tr>\n", "<tr>\n", "    <td><b>Actual: Yes</b></td>\n", "    <td style=\"text-align: center\">60</td>\n", "    <td style=\"text-align: center\">40</td>\n", "    <td style=\"text-align: center\">100</td>\n", "</tr>\n", "<tr style=\"border: none\">\n", "    <td style=\"border: none\"></td>\n", "    <td style=\"text-align: center\">90</td>\n", "    <td style=\"text-align: center\">50</td>\n", "</tr>\n", "\n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- **BONUS:** Calculate the true negative rate and false negative rate for that confusion matrix."]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Example\n", "\n", "The true positive and false positive rates gives us a much clearer picture of where predictions begin to fall apart."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["admissions_path = Path('..', 'assets', 'data', 'admissions.csv')\n", "admissions = pd.read_csv(admissions_path).dropna()\n", "admissions.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import model_selection\n", "\n", "# Split data, train model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Score model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Compare to null model\n", "# first create an array with the same shape as y\n", "# then fill it in with the most common value -- numpy \"broadcasts\" the sum over the whole array\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import metrics\n", "\n", "## then compare predicting the mean every time to the true values\n", "null_accuracy = metrics.accuracy_score(null_pred, y_test)\n", "null_accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Get the confusion matrix\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (2 mins.)**\n", "\n", "- What is our model doing?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- What is the model's accuracy on the test set?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- What is the model's true positive rate on the test set?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- What is the model's false positive rate on the test set?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Change the classification threshold for our model to get different predictions.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Use crosstab to get the confusion matrix with labeled rows and columns\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (3 mins.)**\n", "\n", "- What is the model's accuracy on the test set?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- What is the model's true positive rate on the test set?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- What is the model's false positive rate on the test set?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Accuracy\n", "\n", "**Advantages:**\n", "\n", "- Intuitive: it's a lot like an exam score where you get total correct/total attempted.\n", "\n", "**Disadvantages:**\n", "\n", "- Potentially misleading: Can look OK when model is just outputting the most common label.\n", "    - Particularly bad when classes are imbalanced -- e.g. train doesn't break 99% of the time, so a model that always says \"won't break\" has 99% accuracy -- but it fails exactly when we need it!\n", "- Doesn't account for relative costs of false positives and false negatives.\n", "- Doesn't say anything about how far predicted probabilities are from the correct labels."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Other metrics to investigate:**\n", "    \n", "- **Classification error:** Proportion of incorrect predictions (1-accuracy, lower is better).\n", "- **Receiver Operating Characteristic (ROC) curves:** True positive rate vs. false positive rate across all possible threshold probabilities. The **area under the ROC curve** (AUC) is a measure of how well your model performs overall across those thresholds.\n", "  - Allows you to visualize the performance of your classifier across all possible classification thresholds, thus helping you to choose a threshold that appropriately balances true positives and false positives.\n", "  - Still useful when there is high class imbalance (unlike classification accuracy/error).\n", "  - Harder to use when there are more than two response classes.\n", "- **Log loss**: Measures how far the output probabilities are from the correct labels. (Useful when you want to make expected value calculations with those probabilities or triage cases for further attention.)\n", "- **True Negative Rate**, **False Negative Rate**\n", "- **Recall** (a.k.a. True Positive Rate), **Precision** (proportion of positive predictions that are true)\n", "\n", "These measures are all readily available in sklearn."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Lesson Review\n", "\n", "- Does logistic regression address regression or classification problems?\n", "- What do the coefficients in a logistic regression represent? How is the way we interpret them different from how we interpret coefficients in a linear regression model? How is it similar?\n", "- Why isn't accuracy all you need to evaluate classification models?\n", "- How can you tune a model based on the relative costs of false positives and false negatives?"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.1"}}, "nbformat": 4, "nbformat_minor": 2}