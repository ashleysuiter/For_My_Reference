{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    " \n",
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification vs. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regression model predicts the value of a numeric variable. We evaluate it by measuring *how close its predictions are* to ground-truth values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification model predicts the value of a categorical variable. Many classification models provide *probability distributions* over possible values, in addition to a \"hard\" prediction. We can evaluate classification models by measuring how close those probabilities are to the correct values (0 or 1), but more often we evaluate them according to *how often their (hard) predictions are correct.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise (2 mins.)** Slack poll.\n",
    "\n",
    "/poll “Which of the following are classification (as opposed to regression) problems? (Select all that apply.)” “Predicting how many people will come to a meetup event.” “Predicting which of the people who signed up for a meetup will actually attend.” “Predicting the price that a house will sell for, based on its zip code and square footage.” “Assigning probabilities of experiencing a fire in the next six months to buildings in a city.” “Identifying animals in photographs by species.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite its name, logistic regression is a type of classification model. More specifically, it addresses *binary classification* problems, where we are classifying items into either of two categories. We will see that it is a fairly minimal modification of linear regression to adapt it to such problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use logistic regression to predict who will survive on the titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('../assets/data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get us started, use just the numeric columns without missing data\n",
    "titanic = titanic.select_dtypes(['int64', 'float64']).dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the column `y` we want to predict and the \n",
    "# columns `X` we will use to make the predictions\n",
    "target_col = 'Survived'\n",
    "X = titanic.drop(target_col, axis='columns')\n",
    "y = titanic.loc[:, target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aside 25% of the data for testing the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import a model class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a model from that class\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Ask the model to learn a function that predicts `y` from `X`\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6636771300448431"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the model on the test data\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model gets the right answer 68% of the time on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that any good? Well, let's see what percent of the passengers survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we guessed \"did not survive\" every time, we would get 62% accuracy. Our model is doing a bit better than that, so it is getting some signal from our feature variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All that changes in the code when we go from linear to logistic regression is the model class that we import and instantiate and the type of column that we use as our target.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise (10 mins., in pairs)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the dataset at ../assets/data/iris.csv into a Pandas DataFrame called `iris`. This dataset contains measurements of iris petals and sepal leaves (the leaves just below the petal) and a label indicating the iris's species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a new Boolean column \"is_virginica\" that indicates whether the value of the \"species\" column is \"Iris-virginica\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create variables `X_train`, `X_test`, `y_train`, `y_test` using a 75/25 train/test split with \"is_virginica\" as the target variable and the four petal and sepal measurements as the feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the training set to train a logistic regression model to predict \"is_virginica\" from the four petal and sepal measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the model's accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare this score with the best score you could get by guessing \"is Virginica\" or \"is not Virginica\" every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **BONUS:** Evaluate your model with k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **BONUS:** Try different combinations of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with One Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to identify the source of a shard of glass is valuable for crime scene forensics. Let's build a model to predict whether a sample of glass is \"window glass\" or \"household glass\" based on its composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load glass data\n",
    "glass_filepath = '../assets/data/glass.csv'\n",
    "glass = pd.read_csv(glass_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change columns to something more uniform\n",
    "glass.columns = ['ri', 'na', 'mg', 'al', 'si', 'k', 'ca', 'ba', 'fe', 'glass_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ri     na    mg    al     si     k    ca   ba   fe  glass_type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0           1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0           1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0           1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0           1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0           1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    70\n",
       "2    76\n",
       "3    17\n",
       "5    13\n",
       "6     9\n",
       "7    29\n",
       "Name: glass_type, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect \"glass_type\"\n",
    "glass['glass_type'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glass types 1-4 are \"window glass,\" and types 4-7 are \"household glass.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"household\" column that we can predict with a binary classification model\n",
    "glass['household'] = (glass.loc[:,'glass_type']>4).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "      <th>household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.51721</td>\n",
       "      <td>12.87</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.33</td>\n",
       "      <td>73.04</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.52177</td>\n",
       "      <td>13.20</td>\n",
       "      <td>3.68</td>\n",
       "      <td>1.15</td>\n",
       "      <td>72.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.51793</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.41</td>\n",
       "      <td>72.64</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.51851</td>\n",
       "      <td>13.20</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.07</td>\n",
       "      <td>72.83</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.41</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.51969</td>\n",
       "      <td>12.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.65</td>\n",
       "      <td>73.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>11.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca    ba    fe  glass_type  \\\n",
       "27   1.51721  12.87  3.48  1.33  73.04  0.56   8.43  0.00  0.00           1   \n",
       "124  1.52177  13.20  3.68  1.15  72.75  0.54   8.52  0.00  0.00           2   \n",
       "26   1.51793  13.21  3.48  1.41  72.64  0.59   8.43  0.00  0.00           1   \n",
       "141  1.51851  13.20  3.63  1.07  72.83  0.57   8.41  0.09  0.17           2   \n",
       "167  1.51969  12.64  0.00  1.65  73.75  0.38  11.53  0.00  0.00           5   \n",
       "\n",
       "     household  \n",
       "27           0  \n",
       "124          0  \n",
       "26           0  \n",
       "141          0  \n",
       "167          1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect 5 random rows\n",
    "glass.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a scatter plot comparing `al` and `household`\n",
    "ax = glass.plot(kind = 'scatter',x= 'al',y='household', alpha =.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression would find a straight line through these points, but a straight line is not appropriate for a classification problem. We know that the right answer is either zero or one, so it is silly to predict a number that is less than zero or greater than one, as we will have to do for some input if we predict using a straight line that has non-zero slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../assets/images/linear_classification.png\" style=\"height: 200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more appropriate shape would be a sigmoid (kind of a flattened \"s\" shape):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../assets/images/logistic_classification.png\" style=\"height: 200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's what logistic regression gives us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into feature columns and target column\n",
    "target_col = 'household'\n",
    "feature_cols = ['al']\n",
    "\n",
    "X=glass.loc[:,feature_cols]\n",
    "y = glass.loc[:,target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training rows and test rows\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model class\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148148148148148"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.722222\n",
       "1    0.277778\n",
       "Name: household, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare to the frequency of the most common class to make sure your accuracy is higher\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83788455, 0.16211545],\n",
       "       [0.63210679, 0.36789321],\n",
       "       [0.77961659, 0.22038341],\n",
       "       [0.86093931, 0.13906069],\n",
       "       [0.51795642, 0.48204358],\n",
       "       [0.7114321 , 0.2885679 ],\n",
       "       [0.86308675, 0.13691325],\n",
       "       [0.71512437, 0.28487563],\n",
       "       [0.43705597, 0.56294403],\n",
       "       [0.77961659, 0.22038341],\n",
       "       [0.86308675, 0.13691325],\n",
       "       [0.07771651, 0.92228349],\n",
       "       [0.74361388, 0.25638612],\n",
       "       [0.8034293 , 0.1965707 ],\n",
       "       [0.90205822, 0.09794178],\n",
       "       [0.80906951, 0.19093049],\n",
       "       [0.73315218, 0.26684782],\n",
       "       [0.74704079, 0.25295921],\n",
       "       [0.8565597 , 0.1434403 ],\n",
       "       [0.9619968 , 0.0380032 ],\n",
       "       [0.81997708, 0.18002292],\n",
       "       [0.82783418, 0.17216582],\n",
       "       [0.81997708, 0.18002292],\n",
       "       [0.8034293 , 0.1965707 ],\n",
       "       [0.78878147, 0.21121853],\n",
       "       [0.84510772, 0.15489228],\n",
       "       [0.82262676, 0.17737324],\n",
       "       [0.8034293 , 0.1965707 ],\n",
       "       [0.87340858, 0.12659142],\n",
       "       [0.91267039, 0.08732961],\n",
       "       [0.84510772, 0.15489228],\n",
       "       [0.61515861, 0.38484139],\n",
       "       [0.81458524, 0.18541476],\n",
       "       [0.78575787, 0.21424213],\n",
       "       [0.7114321 , 0.2885679 ],\n",
       "       [0.7669586 , 0.2330414 ],\n",
       "       [0.82524576, 0.17475424],\n",
       "       [0.82262676, 0.17737324],\n",
       "       [0.76371618, 0.23628382],\n",
       "       [0.84272966, 0.15727034],\n",
       "       [0.56276677, 0.43723323],\n",
       "       [0.16201762, 0.83798238],\n",
       "       [0.81997708, 0.18002292],\n",
       "       [0.66901943, 0.33098057],\n",
       "       [0.48186371, 0.51813629],\n",
       "       [0.7947346 , 0.2052654 ],\n",
       "       [0.68869479, 0.31130521],\n",
       "       [0.56720404, 0.43279596],\n",
       "       [0.84745632, 0.15254368],\n",
       "       [0.8713989 , 0.1286011 ],\n",
       "       [0.81458524, 0.18541476],\n",
       "       [0.92725587, 0.07274413],\n",
       "       [0.38895307, 0.61104693],\n",
       "       [0.73315218, 0.26684782]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New method: get the model's probabilities for the test data.\n",
    "# Return value is a 2D array where each row corresponds to an item in the test set\n",
    "# and each column corresponds to a value of the target variable (0 or 1 in this case).\n",
    "y_pred_prop = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot predictions and predicted probability as a function of our feature\n",
    "x_grid = np.linspace(start= glass.loc[:, 'al'].min(), stop=glass.loc[:, 'al'].max(), num=100)\n",
    "pred_probs =lr.predict_proba(x_grid.reshape(-1,1))[:,1]\n",
    "preds = lr.predict(x_grid.reshape(-1,1))\n",
    "ax = glass.plot(kind='scatter', x='al', y='household', alpha=.2)\n",
    "ax.plot(x_grid, pred_probs, c='r')\n",
    "ax.plot(x_grid, preds, c='g');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicts \"household\" exactly when the probability it assigns to household is above .5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise (5 mins., in pairs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('../assets/data/iris.csv')\n",
    "\n",
    "iris.loc[:, 'is_virginica'] = (iris.loc[:, 'species'] == 'Iris-virginica').astype('int')\n",
    "\n",
    "feature_cols = ['sepal_length']\n",
    "target_col = 'is_virginica'\n",
    "X = iris.loc[:, feature_cols]\n",
    "y = iris.loc[:, target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot predictions and predicted probability against \"sepal_length\" for the model above that predicts \"is_virginica\" from petal_length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How does this plot look different from the corrsponding plot for the previous model? Why does it look that way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted probability curve is flatter because the relationship between the feature and the target is weaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **BONUS:** Generate analogous plots for the other features in the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression With Multiple Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For logistic regression with two features, we can visualize the *decision boundary* it draws between the two classes in terms of those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model to predict whether glass is \"household\"\n",
    "# from its aluminum and magnesium content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the points and the model's decision boundary\n",
    "coefs = lr.coef_[0]\n",
    "intercept = lr.intercept_\n",
    "\n",
    "x_values = np.array([X.loc[:, 'al'].min(), X.loc[:, 'al'].max()])\n",
    "y_values = (-1./coefs[1]) * (coefs[0] * x_values + intercept)\n",
    "colors = np.where(y == 0, 'r', 'b')\n",
    "\n",
    "ax = X.plot(kind='scatter', x='al', y='mg', color=colors)\n",
    "ax.plot(x_values, y_values, label='Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the model predicts \"household\" (blue) for everything below the decision boundary and \"not household\" (red) for everything above it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not give the model nonlinear transformations of the input features to work with, then **the logistic regression decision boundary is always a straight line**.\n",
    "\n",
    "With three features, it is a plane.\n",
    "\n",
    "In general, it is a \"hyperplane.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Looking Inside the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Log-Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression:** *Continuous response* is modeled as a linear combination of the features:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots$$\n",
    "\n",
    "**Logistic regression:** *Log odds* of a binary variable is modeled as a linear combination of the features:\n",
    "\n",
    "$$\\log \\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 x + \\beta_2 x_2 + \\ldots$$\n",
    "\n",
    "where $p$ is the probability of the \"positive\" class (\"household\" in our example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-odds $\\log\\frac{p}{1-p}$ rescales the probability $p$ to go from $-\\infty$ to $\\infty$, so that modeling the log-odds with a line that goes off to $\\infty$ and $\\infty$ is no longer a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a table of log odds in relation to probability\n",
    "log_odds = pd.DataFrame({'probability': np.linspace(0, 1, 11)})\n",
    "log_odds.loc[:, 'log odds'] = np.log(log_odds.probability / (1 - log_odds.probability))\n",
    "log_odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving for $p$ gives us an expression for the estimated probability $\\hat{p}$ in terms of $\\beta_0$, $\\beta_1$, and $x$:\n",
    "\n",
    "$$\\hat{p} = \\frac{e^{\\beta_0 + \\beta_1x}} {1 + e^{\\beta_0 + \\beta_1x}}$$\n",
    "\n",
    "As shown below, the plot of this equation as a function of $x$ has a sigmoid shape. **Changing $\\beta_0$ shifts the curve horizontally, while changing $\\beta_1$ changes how sharply it rises.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run the line below if you do not have bokeh installed\n",
    "# !conda install -y bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an interactive plot of probability as a function of x,\n",
    "# with sliders for b0 and b1\n",
    "from bokeh.layouts import row, column\n",
    "from bokeh.models import CustomJS, Slider\n",
    "from bokeh.plotting import figure, output_notebook, show, ColumnDataSource\n",
    "\n",
    "x = np.linspace(-10, 10, 500)\n",
    "y = np.exp(x) / (1 + np.exp(x))\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "\n",
    "plot = figure(plot_width=400, plot_height=400)\n",
    "\n",
    "plot.line('x', 'y', source=source, line_width=3, line_alpha=0.6)\n",
    "\n",
    "callback = CustomJS(args=dict(source=source), code=\"\"\"\n",
    "    var data = source.data;\n",
    "    var b0 = beta0.value;\n",
    "    var b1 = beta1.value;\n",
    "    var x = data['x']\n",
    "    var y = data['y']\n",
    "    for (var i = 0; i < x.length; i++) {\n",
    "        y[i] = (\n",
    "        Math.pow(Math.E, b0 + b1 * x[i]) \n",
    "        / (1 + Math.pow(Math.E, b0 + b1 * x[i])));\n",
    "    }\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "\n",
    "b0_slider = Slider(start=-10, end=10, value=0, step=.1,\n",
    "                   title=\"beta_0\", callback=callback)\n",
    "callback.args['beta0'] = b0_slider\n",
    "\n",
    "b1_slider = Slider(start=-10, end=10, value=1, step=.1,\n",
    "                   title=\"beta_1\", callback=callback)\n",
    "callback.args['beta1'] = b1_slider\n",
    "\n",
    "layout = row(\n",
    "    plot,\n",
    "    column(b0_slider, b1_slider),\n",
    ")\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Regression Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression:**\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots$$\n",
    "\n",
    "- $\\beta_0$ tells you the model's prediction for $y$ when all input features are zero.\n",
    "- $\\beta_1$ tells you how the model's prediction for $y$ changes with a one-unit increase in $x_1$ when all other variables remain the same. (And similarly for $\\beta_2$, $\\beta_3$, $\\ldots$.)\n",
    "\n",
    "**Logistic regression:**\n",
    "\n",
    "$$\\log \\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 x + \\beta_2 x_2 + \\ldots$$\n",
    "\n",
    "- $\\beta_0$ tells you the model's prediction for the *log odds of $y$* when all input features are zero.\n",
    "- $\\beta_1$ tells you how the model's prediction for *the log odds of* $y$ changes with a one-unit increase in $x_1$ when all other variables remain the same. (And similarly for $\\beta_2$, $\\beta_3$, $\\ldots$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bottom line:** A positive coefficient means that the predicted log odds of the response (and thus the predicted probability) increases with the associated variable, while a negative coefficient means that it decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logistic regression beta values](../assets/images/logistic_betas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Logistic regression addresses a binary classification problem by modeling the *log odds* that an individual is in the class as a linear function of the model features.\n",
    "- A coefficient in a logistic regression model tells you *how the log odds that the model predicts changes* with a one-unit increase in the associated input feature, while other features remain unchanged.\n",
    "- The model's log-odds predictions can be transformed into probabilities.\n",
    "- Those predicted probabilities follow an \"s\" (sigmoid) shape that is bounded by 0 and 1, as a function of the input features.\n",
    "- Those predicted probabilities can be converted into \"hard\" class predictions by mapping everything above a threshold (often .5) to 1 and everything below it to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Comparing Logistic Regression to Other Models\n",
    "\n",
    "Advantages of logistic regression:\n",
    "\n",
    "- Somewhat interpretable.\n",
    "- Training and prediction are fast.\n",
    "- Outputs probabilities.\n",
    "- Features don't need scaling.\n",
    "- Can perform well with a small number of observations.\n",
    "\n",
    "Disadvantages of logistic regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the log odds of the response.\n",
    "- Performance is (generally) not competitive with the best supervised learning methods.\n",
    "- Can't automatically learn feature interactions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
