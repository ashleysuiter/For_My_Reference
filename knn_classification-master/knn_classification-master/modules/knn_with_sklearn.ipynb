{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n", "\n", "#  K-Nearest Neighbors with scikit-learn\n", "\n", "_Authors: Alex Sherman (DC)_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"overview-of-the-iris-dataset\"></a>\n", "## Loading the Iris Data Set\n", "---\n", "\n", "#### Read the iris data into a pandas DataFrame, including column names."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "from pathlib import Path\n", "\n", "# not necessary with newest versions of Jupyter\n", "%matplotlib inline\n", "\n", "# Increase default figure and font sizes for easier viewing.\n", "plt.rcParams['figure.figsize'] = (8, 6)\n", "plt.rcParams['font.size'] = 14\n", "\n", "plt.style.use('fivethirtyeight')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = Path('..', 'assets', 'data', 'iris.data') # Works better cross-platform than hard-coding path as a string\n", "iris = pd.read_csv(data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["iris.head(30)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"terminology\"></a>\n", "\n", "- **150 observations** (n=150): Each observation is one iris flower.\n", "- **Four features** (p=4): sepal length, sepal width, petal length, and petal width.\n", "- **Response**: One of three possible iris species (setosa, versicolor, or virginica)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["![](../assets/images/petal_sepal.jpeg)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In the last two lessons, we built models to predict **numeric variables**, such as median housing prices. Predicting a continuous quantity in this way is called **regression**.\n", "\n", "In the next few lessons, we build models to predict **categorical variables**, such as flower species. Predicting a discrete value in this way is called **classification**."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"exercise-human-learning-with-iris-data\"></a>\n", "## Guided Practice: \"Human Learning\" With Iris Data\n", "\n", "**Question:** Can we predict the species of an iris using petal and sepal measurements? Together, we will:\n", "\n", "1. Read the iris data into a Pandas DataFrame, including column names.\n", "2. Gather some basic information about the data.\n", "3. Use sorting, split-apply-combine, and/or visualization to look for differences between species.\n", "4. Write down a set of rules that could be used to predict species based on iris measurements.\n", "\n", "Define a function that accepts a row of data and returns a predicted species. Then, use that function to make predictions for all existing rows of data and check the accuracy of your predictions."]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Gather some basic information about the data."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Get the number of rows and columns in the iris dataset.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Check the data types\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Verify the basic stats look appropriate\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Test for imbalanced classes\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Verify we are not missing any data\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Use sorting, split-apply-combine, and/or visualization to look for differences between species."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Mean of all numeric columns, grouped by species.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Box plot of petal_width, grouped by species.\n", "# Using .boxplot() convenience method, which returns its Axes\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Box plot of all numeric columns, grouped by species.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Map species to a numeric value so that plots can be colored by species.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["iris.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Scatterplot of petal_length vs. petal_width, colored by species\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Ack -- continuous colorbar is not appropriate.\n", "# Better approach:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Scatter matrix of all features, colored by species.\n", "# scatter_matrix returns 2D array of Axes\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (3 mins.)**\n", "\n", "To illustrate how classifiers work, write down a set of rules for classifying iris species in the following form:\n", "\n", "1. If XYZ, choose Species A.\n", "2. Otherwise if ABC, choose Species B.\n", "3. Otherwise, choose Species C.\n", "\n", "Don't expect perfect results -- in real machine learning problems, perfect accuracy is impossible."]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "#### Example"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define a new feature that represents petal area (\"feature engineering\").\n", "# As iris petals are more ovular shaped as opposed to rectangular,\n", "# we're going to use the formula for area of an ellipse:\n", "# r1 * r2 * 3.14.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Description of petal_area, grouped by species.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Box plot of petal_area, grouped by species.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Only show irises with a petal_area between 5 and 8.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["My set of rules for predicting species:\n", "\n", "- If petal_area is less than 2, predict **setosa**.\n", "- Else if petal_area is less than 6, predict **versicolor**.\n", "- Otherwise, predict **virginica**."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (6 mins.)** Implement these rules to make your own classifier!\n", "\n", "Write a function that accepts a row of data and returns a predicted species. Then, apply that function to `iris` to make predictions for all existing rows of data and check the accuracy of your predictions."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Starter code\n", "\n", "def predict_flower(row):\n", "    if row.loc['petal_area'] < 2:\n", "        prediction = 'Iris-setosa'\n", "#     What about the other cases?\n", "    return prediction\n", "\n", "# Apply your classifier row-wise\n", "iris.loc[:, 'prediction'] = None\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Examine results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["iris.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Let's see what percentage your manual classifier gets correct!\n", "# 0.3333 means 1/3 are classified correctly\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create a scatterplot of PETAL LENGTH versus PETAL WIDTH and color by SPECIES and by PREDICTED SPECIES.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"human-learning-on-the-iris-dataset\"></a>\n", "## Human Learning on the Iris Data Set\n", "---\n", "\n", "How did we (as humans) predict the species of an iris?\n", "\n", "1. We observed that the different species had (somewhat) dissimilar measurements.\n", "2. We focused on features that seemed to correlate with the response.\n", "3. We created a set of rules (using those features) to predict the species of an unknown iris.\n", "\n", "We assumed that if an **unknown iris** had measurements similar to **previous irises**, then its species was most likely the same as those previous irises."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"k-nearest-neighbors-knn-classification\"></a>\n", "## K-Nearest Neighbors (KNN) Classification\n", "---\n", "\n", "Predict that the value of the target variable for an iris is the most popular value among its K \"nearest neighbors.\"\n", "\n", "Which points count as \"nearest neighbors\" depend on how you measure distance. The most common approach is to use Euclidean distance (square root of the sum of squared differences) in the feature space. \n", "\n", "The plots below illustrate KNN for various k and two features: `x='sepal_length'` and `y='sepal_width'`. The points are the values in the training set, and the background colors indicate what we would predict for values in the test set."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"knn-classification-map-for-iris-k\"></a>\n", "### KNN Classification Map for Iris (K=1)\n", "\n", "![1NN classification map](../assets/images/iris_01nn_map.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### KNN Classification Map for Iris (K=5)\n", "\n", "![5NN classification map](../assets/images/iris_05nn_map.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### KNN Classification Map for Iris (K=15)\n", "\n", "![15NN classification map](../assets/images/iris_15nn_map.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"knn-classification-map-for-iris-k\"></a>\n", "### KNN Classification Map for Iris (K=50)\n", "\n", "![50NN classification map](../assets/images/iris_50nn_map.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (2 mins., post to Slack right away.)**\n", "\n", "- How does increasing $k$ affect the bias and the variance of a KNN model?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- How can you choose a good $k$ for a particular application?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# KNN Applied to NBA Stats"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For the rest of the lesson, we will be using a dataset containing the 2015 season statistics for ~500 NBA players. This dataset leads to a nice choice of K, as we'll see below. The columns we'll use for features (and the target 'pos') are:\n", "\n", "\n", "| Column | Meaning |\n", "| ---    | ---     |\n", "| pos | C: Center. F: Front. G: Guard |\n", "| ast | Assists per game | \n", "| stl | Steals per game | \n", "| blk | Blocks per game |\n", "| tov | Turnovers per game | \n", "| pf  | Personal fouls per game | \n", "\n", "For information about the other columns, see [this glossary](https://www.basketball-reference.com/about/glossary.html)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Read the NBA data into a DataFrame.\n", "path = Path('..', 'assets', 'data', 'NBA_players_2015.csv')\n", "nba = pd.read_csv(path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nba.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nba.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Map positions to numbers.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create feature matrix (X).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create response vector (y).\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"using-the-traintest-split-procedure-k\"></a>\n", "### Using the Train/Test Split Procedure (K=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import estimator class and other sklearn tools\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 1. Split X and y into training and testing sets (using `random_state` for reproducibility).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 2. Train the estimator on the training set (using K=1).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# 3. Test the estimator on the testing set and check the accuracy.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Repeat for K=50.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (2 mins., post to Slack right away)**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- What accuracy would you expect a KNN model with $k=1$ to achieve on the *training set*? Would we expect accuracy on the training set to be higher or lower with $k=50$?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Comparing Testing Accuracy With Null Accuracy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For a classification model, a null model **always predicts the most frequent class**. For example, if most players in our data set are Centers, we would always predict Center. It is important to make sure that your model is outperforming the null model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# first create an array with the same shape as y\n", "# then fill it in with the most common value -- numpy \"broadcasts\" the sum over the whole array\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# # then compare predicting the mean every time to the true values\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"tuning-a-knn-model\"></a>\n", "## Getting Probabilities from a KNN Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Instantiate the estimator class (using the value K=5).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Fit the estimator with data.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["A classification estimator's `.predict` method returns the estimator's \"categorical\" predictions -- in this case, 0, 1, or 2 indicating whether the estimator thinks each player is most likely a center, forward, or guard.\n", "\n", "A classification estimator also has a `.predict_proba` method that returns the *probabilities* that the estimator assigns to each class -- in this case, the probability that a given player is a center, is a forward, or is a guard. The `predict` method just returns the class corresponding to the highest of these probabilities.\n", "\n", "For KNN, the probabilities that `.predict_proba` returns are just the class frequencies among the given point's K neareset neighbors."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Calculate predicted probabilities of class membership.\n", "# Each row sums to one and contains the probabilities of the point being a 0-Center, 1-Front, 2-Guard.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"what-happen-if-we-view-the-accuracy-of-our-training-data\"></a>\n", "### Accuracy as a Function of $k$"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Store k and associated training scores in a DataFrame\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Plot training scores against k\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (2 mins., post to Slack right away.)**\n", "\n", "- Why does the accuracy on the training set decrease as $k$ increases?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Search for the \"best\" value of K."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Calculate TRAINING ERROR and TESTING ERROR for K=1 through 100.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add test scores to `scores_df`\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot test scores against k\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot train scores and test scores together\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Find the minimum testing error and the associated K value.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- **Training error** decreases as model complexity increases (lower value of K).\n", "- **Testing error** is minimized at the optimum model complexity."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Evaluating training and testing error:**\n", "\n", "- If training error is unacceptably high, then you have a bias problem.\n", "- If training error is low enough but there is a big gap between training and test error, then you have a variance problem."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Conclusions**\n", "\n", "- When using KNN on this data set with these features, the **best value for K** is likely to be around 14.\n", "- Given the statistics of an **unknown player**, we estimate that we would be able to correctly predict his position about 74% of the time."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"standardizing-features\"></a>\n", "## Standardizing Features\n", "---\n", "\n", "Many machine learning models are sensitive to feature scale. \n", "\n", "> KNN in particular is sensitive to feature scale because it (by default) uses the Euclidean distance metric. To determine closeness, Euclidean distance sums the square difference along each axis. So, if one axis has large differences and another has small differences, the former axis will contribute much more to the distance than the latter axis.\n", "\n", "This means that it matters whether our feature are centered around zero and have similar variance to each other."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In the case of KNN on the iris data set, imagine we measure sepal length in kilometers, but we measure sepal width in millimeters. Our data will show variation in sepal width, but almost no variation in sepal length.\n", "\n", "Unfortunately, KNN cannot automatically adjust to this. Other models tend to struggle with scale as well, even linear regression, when you get into more advanced methods such as regularization."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fortunately, this is an easy fix."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"use-standardscaler-to-standardize-our-data\"></a>\n", "### Use `StandardScaler` to Standardize our Data\n", "\n", "StandardScaler standardizes our data by subtracting the mean from each feature and dividing by its standard deviation."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create feature matrix (X).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create the train/test split.\n", "# Notice that we create the train/test split first before fitting the StandardScaler\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Instantiate and fit `StandardScaler`.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Fit a KNN estimator and look at the testing error.\n", "Can you find a number of neighbors that improves our results from before?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Calculate testing error.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<a id=\"comparing-knn-with-other-models\"></a>\n", "## Comparing KNN With Other Models\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Advantages of KNN:**\n", "\n", "- It's simple to understand and explain.\n", "- Model training is fast.\n", "- It can be used for classification and regression! (For regression, take the average value of the K nearest points.)\n", "- Being a non-parametric method, it is often successful in classification situations where the decision boundary is very irregular.\n", "\n", "**Disadvantages of KNN:**\n", "\n", "- It must store all of the training data.\n", "- Its prediction phase can be slow when n is large.\n", "- It is sensitive to irrelevant features.\n", "- It is sensitive to the scale of the data.\n", "- Accuracy is (generally) not competitive with the best supervised learning methods."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.1"}}, "nbformat": 4, "nbformat_minor": 2}