# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Train-Test Splits and the Bias-Variance Tradeoff

## Student Requirements

Before this lesson, you should be able to...

- Load a CSV into a Pandas DataFrame
- Perform statistical exploration with Pandas
- Create simple data visualizations with matplotlib

## Learning Objectives

After this lesson, you should be able to...

- Explain how error due to bias and error due to variance arise
- Describe what overfitting and underfitting means in the context of model building
- Identify how various changes to a model will affect its bias and variance
- Explain why it is necessary to evaluate a model on a held-out data set
- Perform simple train/test splits and KFold cross-jvalidation

## Lesson Modules

- [Bias and Variance](./modules/bias_and_variance.ipynb)
- [Train/Test Splits](./modules/train_test_split.ipynb)

## Additional Resources

- [Understanding the Bias-Variance Tradeoff](http://scott.fortmann-roe.com/docs/BiasVariance.html)
- [An Intuitive Explanation of Overfitting](https://www.quora.com/What-is-an-intuitive-explanation-of-overfitting/answer/Jessica-Su)
- [More Train-Test split resources](https://git.generalassemb.ly/AdiBro/Resources/blob/master/Machine-Learning.md#train-test-split-cross-validation-and-bias-variance-tradeoff)
- [More Bias-Variance Tradeoff resources](https://git.generalassemb.ly/AdiBro/Resources/blob/master/Statistics.md#bias-variance-tradeoff)
