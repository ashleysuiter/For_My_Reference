{"cells": [{"cell_type": "markdown", "metadata": {"toc-hr-collapsed": false}, "source": ["<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n", " \n", "# Ensembles and Random Forests\n", " \n", "_Author: Joseph Nelson (DC)_\n", "\n", "*Adapted from Chapter 8 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)*"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import numpy as np\n", "import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {"toc-hr-collapsed": true}, "source": ["## Getting Started"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Random Forest Regression"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (6 mins., in pairs).**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Build a random forest regression model on the numeric features of the Ames housing dataset at `../assets/data/ames_train.csv`. You will need to import `RandomForestRegressor` from scikit-learn's `ensemble` module. Set `n_estimators=200` when you instantiate the regressor. Do a simple train/test split, train on all numeric features without null values, and get R2 values for both the training set and the test set."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Is the model overfitting, underfitting, both, or neither? How do you know?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- **BONUS:** Create a `RandomForestRegressor` estimator that gets a better score on the test set."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A random forest is a collection of decision trees. A random forest regressor makes a prediction by averaging the predictions from its constituent decision trees. Each tree is trained somewhat differently so that they will make different kinds of errors that will tend to cancel out."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Random Forest Classification"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (5 mins., in pairs).**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Build a random forest classifier model `rfc` on the numeric features of the Titanic dataset at `../assets/data/titanic.csv`. Do not use `PassengerId` as a feature. You will need to import `RandomForestClassifier` from scikit-learn's `ensemble` module. Set `n_estimators=200` and `oob_score=True` when you instantiate the classifier. Do a simple train/test split, train on all numeric features without null values, and get R2 values for both the training set and the test set."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Is the model overfitting, underfitting, both, or neither? How do you know?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- **BONUS:** Modify the model to get a better score on the test set."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A random forest classifier makes a prediction by taking the \"majority vote\" of its constituent decision trees."]}, {"cell_type": "markdown", "metadata": {"toc-hr-collapsed": true}, "source": ["## Ensembling"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Overview"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Ensemble learning (or \"ensembling\")** is the process of combining several predictive models in order to produce a combined model that is more accurate than any individual model. For example, given predictions from several models we could:\n", "\n", "- **Regression:** Take the average of the predictions.\n", "- **Classification:** Take a vote and use the most common prediction.\n", "\n", "For ensembling to work well, the models must be:\n", "\n", "- **Accurate:** They outperform the null model.\n", "- **Independent:** Their predictions are generated using different processes.\n", "\n", "**The big idea:** If you have a collection of individually imperfect (and independent) models, the \"one-off\" mistakes made by each model are probably not going to be made by the rest of the models, and thus the mistakes will be discarded when you average the models.\n", "\n", "There are two basic **methods for ensembling:**\n", "\n", "- Manually ensembling your individual models.\n", "- Using a standard \"meta-model\" that does ensembling internally.\n", "\n", "Random forests are a popular type of \"meta-model.\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Manual Ensembling\n", "\n", "What makes an effective manual ensemble?\n", "\n", "- Different types of **models**.\n", "- Different combinations of **features**.\n", "- Different **tuning parameters**."]}, {"cell_type": "markdown", "metadata": {}, "source": ["![Machine learning flowchart](../assets/images/crowdflower_ensembling.jpg)\n", "\n", "*Machine learning flowchart created by the [winner](https://github.com/ChenglongChen/Kaggle_CrowdFlower) of Kaggle's [CrowdFlower competition](https://www.kaggle.com/c/crowdflower-search-relevance)*."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Comparing Ensembling With a Single-Model Approach\n", "\n", "**Advantage of ensembling:** it can increase predictive accuracy.\n", "\n", "**Disadvantages of ensembling:**\n", "\n", "- It decreases interpretability.\n", "- It takes longer to train.\n", "- It takes longer to predict.\n", "- It is more complex to automate and maintain, particularly with manual ensembling.\n", "\n", "Outside of machine learning competitions, you have to weigh gains in accuracy against added complexity."]}, {"cell_type": "markdown", "metadata": {"toc-hr-collapsed": true}, "source": ["### Bagging"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The primary weakness of **decision trees** is that they don't tend to have the best predictive accuracy. This is partially because of **high variance**, meaning that different splits in the training data can lead to very different trees.\n", "\n", "**Bagging** is a general-purpose procedure for reducing the variance of a machine learning method but is particularly useful for decision trees. Bagging is short for **bootstrap aggregation**, meaning the aggregation of bootstrap samples.\n", "\n", "A **bootstrap sample** is a random sample with replacement. So, it has the same size as the original sample but might duplicate some of the original observations."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Set a seed for reproducibility.\n", "np.random.seed(1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create an array of 1 through 20.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample that array 20 times with replacement.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**How does bagging work (for decision trees)?**\n", "\n", "1. Grow B trees using B bootstrap samples from the training data.\n", "2. Train each tree on its bootstrap sample and make predictions.\n", "3. Combine the predictions:\n", "    - Average the predictions for **regression trees**.\n", "    - Take a vote for **classification trees**.\n", "\n", "**Notes:**\n", "\n", "- **Each bootstrap sample** is typically the same size as the original training set. (It may contain repeated rows.)\n", "- **B** should be a large enough value that the error seems to have \"stabilized\".\n", "- The trees are **grown deep** so that they have low bias/high variance.\n", "\n", "Training multiple trees through bagging can give more consistent results than training a single tree, thereby reducing variance."]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Manually Implementing Bagged Decision Trees (with B=10)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Read in and prepare the vehicle training data.\n", "path = '../assets/data/vehicles_train.csv'\n", "train = pd.read_csv(path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Transform \"vtype\" to \"is_truck\"\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Set a seed for reproducibility.\n", "np.random.seed(123)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create ten bootstrap samples (which will be used to select rows from the DataFrame).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Show the rows for the first decision tree.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Read in and prepare the vehicle testing data.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define testing data.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import decision tree regressor\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Grow one tree for each bootstrap sample and make predictions on testing data.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Convert predictions from list to NumPy array.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Average predictions.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Calculate RMSE.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Bagged Decision Trees in `scikit-learn` (with B=500)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define the training and testing sets.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Instruct BaggingRegressor to use DecisionTreeRegressor as the \"base estimator.\"\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Fit and predict.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Calculate RMSE.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Random Forests\n", "\n", "Random Forests offer a **slight variation on bagged trees** that usually gives better performance:\n", "\n", "- Exactly like bagging, we create an ensemble of decision trees using bootstrapped samples of the training set.\n", "- However, when building each tree, each time a split is considered, a **random sample of m features** is chosen as split candidates from the **full set of p features**. The split is only allowed to use **one of those m features**.\n", "    - A new random sample of features is chosen for **every single tree at every single split**.\n", "    - For **classification**, m is typically chosen to be the square root of p.\n", "    - For **regression**, m is typically chosen to be somewhere between p/3 and p.\n", "\n", "What's the point?\n", "\n", "- Suppose there is **one very strong feature** in the data set. When using bagged trees, most of the trees will use that feature as the top split, resulting in an ensemble of similar trees that are **highly correlated**.\n", "- Averaging highly correlated quantities does not significantly reduce variance (which is the entire goal of bagging).\n", "- By randomly leaving out candidate features from each split, **random forests \"decorrelate\" the trees** to the extent that the averaging process can reduce the variance of the resulting model.\n", "- Another way of looking at it is that sometimes one or two strong features dominate every tree in bagging, resulting in essentially the same tree as every predictor. (This is what was meant when saying the trees could be highly correlated.) By using a subset of features to generate each tree, we get a wider variety of predictive trees that do not all use the same dominant features."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Out-of-Bag Error"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The primary purpose of ensembling is to create a \"team\" of models that performs better than its individual members."]}, {"cell_type": "markdown", "metadata": {}, "source": ["A **side benefit** of bagging is that it allows you to estimate out-of-sample errorwithout using a train/test split or cross-validation!\n", "\n", "For each tree, the observations that were not used in training are called **\"out-of-bag\" observations.**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Show the first bootstrap sample.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Show the \"in-bag\" observations for each sample.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Show the \"out-of-bag\" observations for each sample.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Calculating \"out-of-bag error:\"**\n", "\n", "1. For each observation in the training data, predict its response value using **only** the trees in which that observation was out-of-bag. Average those predictions (for regression) or take a vote (for classification).\n", "2. Compare all predictions to the actual response values in order to compute the out-of-bag error.\n", "\n", "When B is sufficiently large, the **out-of-bag error** is an accurate estimate of **out-of-sample error**."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Compute the out-of-bag R-squared score for `rfc`.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Feature Importance\n", "\n", "Bagging increases **predictive accuracy** but decreases **model interpretability** because it's no longer possible to visualize the tree to understand the importance of each feature.\n", "\n", "However, we can still obtain an overall summary of **feature importance** from bagged models:\n", "\n", "- **Bagged regression trees:** Calculate the total amount that **MSE** decreases due to splits over a given feature, averaged over all trees\n", "- **Bagged classification trees:** Calculate the total amount that **Gini index** decreases due to splits over a given feature, averaged over all trees"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["list(zip(titanic.select_dtypes(['int64', 'float64'])\n", "         .dropna(axis='columns')\n", "         .drop(['Survived', 'PassengerId'], axis='columns'),\n", "    rfc.feature_importances_)\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (6 mins.)**\n", "\n", "In your own words...\n", "\n", "- What is ensembling?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- How do bagged classification trees work?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- How does a random forest differ from an ordinary bagged decision tree?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- What is out-of-bag error?"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- Compare and contrast ensembling and K-fold cross validation in terms of both process and aims."]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {"toc-hr-collapsed": true}, "source": ["## Building and Tuning Random Forests"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Preparing the Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Read in the hitters data.\n", "path = '../assets/data/hitters.csv'\n", "hitters = pd.read_csv(path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Remove rows with missing values.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Encode categorical variables as integers.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create a scatter plot of hits vs years, colored by salary\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define features: Exclude career statistics (which start with \"C\") and the response (salary).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define X and y.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Predicting Salary With a Decision Tree\n", "\n", "Let's first recall how we might predict salary using a single decision tree.\n", "\n", "We'll first find the best **max_depth** for a decision tree using cross-validation:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# List of values to try for max_depth:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Use 10-fold cross-validation with each value of max_depth.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot max_depth (x-axis) versus R^2 (y-axis).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Show the best RMSE and the corresponding max_depth.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# max_depth=2 was best, so fit a tree using that parameter.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Compute feature importances.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Predicting Salary With a Random Forest"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import random forest regressor\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# max_features=5 is best and n_estimators=150 is sufficiently large.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Compute feature importances.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Compute the out-of-bag R-squared score.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Exercise (12 mins., in pairs)**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Use a `RandomForestRegressor` estimator to build a quick first model to predict \"count\" in the `bikes` dataset. Be sure not to use \"casual\" and \"registered\" as features. Measure R^2 using a random test set, ignoring the time-series aspects of the dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["path = '../assets/data/bikeshare.csv'\n", "bikes = pd.read_csv(path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- **BONUS:** Make your model more realistic by taking the test set from the end and time-shifting the variables that cannot be known in advance by two hours."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["- **BONUS:** Improve your model's score, e.g. through feature engineering.\n", "\n", "*Tip:* If you have a small gap between training-set performance and test-set performance, then focus on decreasing bias. Otherwise, focus on decreasing variance."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\blacksquare$"]}, {"cell_type": "markdown", "metadata": {"toc-hr-collapsed": true}, "source": ["### Hyperparameter Tuning"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["from sklearn.ensemble import RandomForestRegressor\n", "rfreg = RandomForestRegressor()\n", "rfreg"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Tuning n_estimators\n", "\n", "One important tuning parameter is **n_estimators**, which represents the number of trees that should be grown. This should be a large enough value that the error seems to have \"stabilized.\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# List of values to try for n_estimators:\n", "estimator_range = list(range(10, 310, 10))\n", "\n", "# List to store the average RMSE for each value of n_estimators:\n", "RMSE_scores = []\n", "\n", "# Use five-fold cross-validation with each value of n_estimators (Warning: Slow!).\n", "for estimator in estimator_range:\n", "    rfreg = RandomForestRegressor(n_estimators=estimator, random_state=1)\n", "    MSE_scores = cross_val_score(rfreg, X, y, cv=5, scoring='neg_mean_squared_error')\n", "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot RMSE (y-axis) versus n_estimators (x-axis).\n", "\n", "fig, ax = plt.subplots()\n", "ax.plot(estimator_range, RMSE_scores);\n", "ax.set_xlabel('n_estimators');\n", "ax.set_ylabel('RMSE (lower is better)');"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Adding more trees will only help average performance, with diminishing returns.**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Tuning max_features\n", "\n", "The other important tuning parameter is **max_features**, which represents the number of features that should be considered at each split."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# List of values to try for max_features:\n", "feature_range = list(range(1, len(feature_cols)+1))\n", "\n", "# List to store the average RMSE for each value of max_features:\n", "RMSE_scores = []\n", "\n", "# Use 10-fold cross-validation with each value of max_features (Warning: Super slow!).\n", "for feature in feature_range:\n", "    rfreg = RandomForestRegressor(n_estimators=150, max_features=feature, random_state=1)\n", "    MSE_scores = cross_val_score(rfreg, X, y, cv=10, scoring='neg_mean_squared_error')\n", "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot max_features (x-axis) versus RMSE (y-axis).\n", "fig, ax = plt.subplots()\n", "ax.plot(feature_range, RMSE_scores);\n", "ax.set_xlabel('max_features');\n", "ax.set_ylabel('RMSE (lower is better)');"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Show the best RMSE and the corresponding max_features.\n", "sorted(zip(RMSE_scores, feature_range))[0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Comparing Random Forests to Decision Trees\n", "\n", "**Advantages of random forests:**\n", "\n", "- Their performance is often competitive with the best supervised learning methods, unlike that of decision trees.\n", "- They provide a more reliable estimate of feature importance.\n", "- They allow you to estimate out-of-sample error without using train/test split or cross-validation.\n", "\n", "**Disadvantages of random forests:**\n", "\n", "- They are less interpretable.\n", "- They are slower to train.\n", "- They are slower to predict."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Which model is best?** The best classifier for a particular task is task-dependent. In many business cases, interpretability is more important than accuracy. So, decision trees may be preferred. In other cases, accuracy on unseen data might be paramount, in which case random forests would likely be better (since they typically overfit less). "]}, {"cell_type": "markdown", "metadata": {"toc-hr-collapsed": true}, "source": ["## Summary"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Ensembling combines several predictive models with the goal of improving accuracy.\n", "- For ensembling to work, the component models need to have different patterns of error that tend to cancel each other out.\n", "- Bagging produces an ensemble of models (often decision trees) by training each one on a bootstrap sample from the original dataset.\n", "- A side benefit of bagging is that out-of-bag scores can be used to estimate generalization performance without a train/test split or cross-validation.\n", "- A random forest is an ensemble of decision trees trained using both bagging and feature subsetting."]}], "metadata": {"kernelspec": {"display_name": "ga", "language": "python", "name": "ga"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.1"}}, "nbformat": 4, "nbformat_minor": 2}